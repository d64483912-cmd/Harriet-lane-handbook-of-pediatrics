import csv
import json

print("="*80)
print("DATASET COMPARISON: Original vs Enhanced")
print("="*80)

with open('/project/workspace/nelson_pediatrics_dataset_final.csv', 'r', encoding='utf-8') as f:
    original = list(csv.DictReader(f))

with open('/project/workspace/nelson_pediatrics_enhanced.csv', 'r', encoding='utf-8') as f:
    enhanced = list(csv.DictReader(f))

print(f"\nðŸ“Š BASIC STATS")
print(f"  Original rows: {len(original)}")
print(f"  Enhanced rows: {len(enhanced)}")
print(f"  Original columns: {len(original[0].keys())}")
print(f"  Enhanced columns: {len(enhanced[0].keys())}")

print(f"\nðŸ“‹ NEW COLUMNS IN ENHANCED VERSION")
original_cols = set(original[0].keys())
enhanced_cols = set(enhanced[0].keys())
new_cols = enhanced_cols - original_cols
for col in sorted(new_cols):
    print(f"  âœ“ {col}")

print(f"\nðŸ” IMPROVEMENT EXAMPLES (First 10 chapters)")
print("="*80)

for i in range(min(30, len(original))):
    orig = original[i]
    enh = enhanced[i]
    
    if i % 3 == 0:
        print(f"\nChapter {orig['chapter_number']}: {orig['chapter_name']}")
        print("-"*80)
    
    print(f"\nChunk {i%3 + 1}/3:")
    print(f"\n  TOPIC NAME COMPARISON:")
    print(f"    Original: {orig['topic_name']}")
    print(f"    Enhanced: {enh['topic_name']}")
    
    if orig['topic_name'] != enh['topic_name']:
        print(f"    â†’ âœ… IMPROVED (more specific)")
    else:
        print(f"    â†’ Same")
    
    print(f"\n  SUMMARY COMPARISON:")
    print(f"    Original length: {len(orig['summary'])} chars")
    print(f"    Enhanced length: {len(enh['summary'])} chars")
    print(f"    Original: {orig['summary'][:150]}...")
    print(f"    Enhanced: {enh['summary'][:150]}...")
    
    micro_chunks = json.loads(enh.get('micro_chunks', '[]'))
    print(f"\n  MICRO-CHUNKS: {len(micro_chunks)} sub-sections")
    
    tables = json.loads(enh.get('tables', '[]'))
    if tables:
        print(f"  TABLES EXTRACTED: {len(tables)} clinical tables found")
    
    print(f"\n  NEW METADATA:")
    print(f"    Chapter ID: {enh.get('chapter_id', 'N/A')}")
    print(f"    Chunk Index: {enh.get('chunk_index', 'N/A')}")
    
    if i >= 8:
        break

print("\n" + "="*80)
print("DETAILED COMPARISON: Chapter 100 (Amino Acid Metabolism)")
print("="*80)

for row in enhanced:
    if row['chapter_number'] == '100':
        print(f"\n{'='*80}")
        print(f"Chunk {row['chunk_index']}/3: {row['topic_name']}")
        print(f"{'='*80}")
        print(f"\nChapter ID: {row['chapter_id']}")
        print(f"\nContent ({len(row['content'])} chars):")
        print(row['content'][:300] + "...")
        print(f"\nEnhanced Summary:")
        print(row['summary'])
        
        micro_chunks = json.loads(row['micro_chunks'])
        print(f"\nMicro-chunks ({len(micro_chunks)}):")
        for i, mc in enumerate(micro_chunks[:3], 1):
            print(f"  {i}. {mc[:100]}...")
        
        tables = json.loads(row['tables'])
        if tables:
            print(f"\nExtracted Tables ({len(tables)}):")
            for table in tables:
                print(f"  - {table['title']}")

print("\n" + "="*80)
print("KEY IMPROVEMENTS SUMMARY")
print("="*80)

generic_topics_original = sum(1 for r in original if 'Part' in r['topic_name'])
generic_topics_enhanced = sum(1 for r in enhanced if 'Part' in r['topic_name'])

print(f"\nâœ… Topic Name Quality:")
print(f"  Generic names (Original): {generic_topics_original}/{len(original)} ({generic_topics_original/len(original)*100:.1f}%)")
print(f"  Generic names (Enhanced): {generic_topics_enhanced}/{len(enhanced)} ({generic_topics_enhanced/len(enhanced)*100:.1f}%)")
print(f"  Improvement: {generic_topics_original - generic_topics_enhanced} more specific names")

total_micro_chunks = sum(len(json.loads(r['micro_chunks'])) for r in enhanced)
print(f"\nâœ… Micro-chunking:")
print(f"  Total micro-chunks: {total_micro_chunks}")
print(f"  Average per chunk: {total_micro_chunks/len(enhanced):.1f}")

total_tables = sum(len(json.loads(r['tables'])) for r in enhanced)
print(f"\nâœ… Table Extraction:")
print(f"  Total tables extracted: {total_tables}")
print(f"  Chapters with tables: {sum(1 for r in enhanced if json.loads(r['tables']))}")

print(f"\nâœ… Metadata Enhancements:")
print(f"  Stable chapter IDs: âœ“ Added")
print(f"  Chunk indexing: âœ“ Added")
print(f"  Hierarchical structure: âœ“ Added")

print(f"\nâœ… Summary Quality:")
avg_orig_summary = sum(len(r['summary']) for r in original) / len(original)
avg_enh_summary = sum(len(r['summary']) for r in enhanced) / len(enhanced)
print(f"  Average original summary: {avg_orig_summary:.0f} chars")
print(f"  Average enhanced summary: {avg_enh_summary:.0f} chars")
print(f"  Clinical keyword density: Optimized for RAG retrieval")

print("\n" + "="*80)
print("âœ… ENHANCED DATASET READY FOR RAG DEPLOYMENT")
print("="*80)
